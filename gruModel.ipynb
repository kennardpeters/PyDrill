{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MIDI path (should already be generated)\n",
    "dataRoot = '/home/kennardpeters/Documents/PyDrillData/'\n",
    "#midi_path = jazzRoot + '/midi/'\n",
    "#new_midi_path = jazzRoot + '/midi/onceuponatimeinspace.mid'\n",
    "#midi = converter.parse(new_midi_path)\n",
    "#parts = list(instrument.partitionByInstrument(midi))\n",
    "#print(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the files\n",
    "with open(os.path.join(dataRoot,'notes_initial_train.json'), 'r') as outfile:\n",
    "  notes_train = json.load(outfile)\n",
    "\n",
    "with open(os.path.join(dataRoot,'notes_initial_test.json'), 'r') as outfile:\n",
    "  notes_test = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input and output sequences\n",
    "\n",
    "def prepare_sequences(notes, note_to_int = None, sequence_length = 32):\n",
    "  network_input = []\n",
    "  network_output = []\n",
    "\n",
    "  if not note_to_int:\n",
    "    # Set of note/chords (collapse into list)\n",
    "    pitch_names = sorted(set(itertools.chain(*notes)))\n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitch_names))\n",
    "\n",
    "  # Loop through all songs\n",
    "  for song in notes:\n",
    "    # Check for the end\n",
    "    i = 0\n",
    "    while i + sequence_length < len(song):\n",
    "      # seq_len notes for the input seq\n",
    "      sequence_in = song[i: i + sequence_length]\n",
    "      # Next note to predict\n",
    "      sequence_out = song[i+sequence_length]\n",
    "      # Return the int representation of the note - *(If note not found)\n",
    "      network_input.append([note_to_int.get(char, 0) for char in sequence_in])\n",
    "      network_output.append(note_to_int.get(sequence_out, 0))\n",
    "      i += sequence_length\n",
    "\n",
    "  n_patterns = len(network_input)\n",
    "\n",
    "  # Reshape for LSTM input\n",
    "  network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "  # Normalize input (?? - CHECK LATER - this assumes the alphabetical order of the notes carries semantic meaning?)\n",
    "  #network_input = network_input / len(pitch_names)\n",
    "  #network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "  return network_input, network_output, note_to_int\n",
    "\n",
    "train_input, train_output, note_to_int = prepare_sequences(notes_train, sequence_length = 64)\n",
    "#test_input, test_output, _ = prepare_sequences(notes_test, note_to_int = note_to_int, sequence_length = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_note = {number:note for note, number in note_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random observation from the network input, return (input, target), each shifted by 1\n",
    "# NOT NEEDED ANYMORE - each epoch just using entire dataset\n",
    "def random_training_set(network_input):    \n",
    "    chunk = network_input[random.randint(0, network_input.shape[0] - 1), : , :]\n",
    "    input = torch.tensor(chunk[:-1], dtype = torch.long).squeeze()\n",
    "    target = torch.tensor(chunk[1:], dtype = torch.long).squeeze()\n",
    "    return input, target\n",
    "\n",
    "\n",
    "def grad_clipping(net, theta):  \n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    \n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationRNN(nn.Module):\n",
    "  # input_size: number of possible pitches\n",
    "  # hidden_size: embedding size of each pitch\n",
    "  # output_size: number of possible pitches (probability distribution)\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(GenerationRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        #self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size * n_layers, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # Creates embedding of the input texts\n",
    "        #print('initial input', input.size())\n",
    "        input = self.embedding(input.view(1, -1))\n",
    "        #print('input after embedding', input.size())\n",
    "        #print('hidden', hidden.size())\n",
    "        #print('hidden[0]', hidden[0].size())\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        #output, hidden = self.lstm(input, hidden)\n",
    "        #print('output after gru', output.size())\n",
    "        #print('hidden after gru', hidden.size())\n",
    "        output = self.decoder(hidden.view(1, -1))\n",
    "        #print('output after decoder', output.size())\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single training step for ONE sequence\n",
    "def train_sequence(input, target, model, optimizer, criterion):\n",
    "    # Initialize hidden state, zero the gradients of model \n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    # For each character in our chunk (except last), compute the hidden and ouput\n",
    "    # Using each output, compute the loss with the corresponding target \n",
    "    for i in range(len(input)):\n",
    "        output, hidden = model(input[i], hidden)\n",
    "        loss += criterion(output, target[i].unsqueeze(0))\n",
    "    \n",
    "    # Backpropagate, clip gradient and optimize\n",
    "    loss.backward()\n",
    "    grad_clipping(model, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return average loss for the input sequence\n",
    "    return loss.data.item() / len(input)\n",
    "\n",
    "def test_sequence(input, target, model, criterion):\n",
    "    # Initialize hidden state, zero the gradients of model \n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    # For each character in our chunk (except last), compute the hidden and ouput\n",
    "    # Using each output, compute the loss with the corresponding target \n",
    "    for i in range(len(input)):\n",
    "        output, hidden = model(input[i], hidden)\n",
    "        loss += criterion(output, target[i].unsqueeze(0))\n",
    "\n",
    "    # Return average loss for the input sequence\n",
    "    return loss.data.item() / len(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall training loop\n",
    "def training_loop(model, optimizer, scheduler, criterion, train_input, test_input):\n",
    "\n",
    "  train_losses = []\n",
    "  test_losses = []\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    # Training - sample 2000\n",
    "    sampled_train_ids = random.choices(range(train_input.shape[0]), k = 2000)\n",
    "    print(scheduler.get_last_lr())\n",
    "    for i in range(train_input.shape[0]):\n",
    "      sequence = train_input[i, : , :]\n",
    "      input = torch.tensor(sequence[:-1], dtype = torch.long).squeeze().to(device)\n",
    "      target = torch.tensor(sequence[1:], dtype = torch.long).squeeze().to(device)\n",
    "      loss = train_sequence(input, target, model, optimizer, criterion)\n",
    "      running_loss += loss\n",
    "\n",
    "    train_epoch_loss = running_loss / 2000\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    running_loss = 0\n",
    "    # model.eval()\n",
    "    # # Testing\n",
    "    # for i in range(test_input.shape[0]):\n",
    "    #   sequence = test_input[i, : , :]\n",
    "    #   input = torch.tensor(sequence[:-1], dtype = torch.long).squeeze().to(device)\n",
    "    #   target = torch.tensor(sequence[1:], dtype = torch.long).squeeze().to(device)\n",
    "    #   loss = test_sequence(input, target, model, criterion)\n",
    "    #   running_loss += loss\n",
    "\n",
    "    # test_epoch_loss = running_loss / 1000\n",
    "    # test_losses.append(test_epoch_loss)\n",
    "    test_epoch_loss = 0\n",
    "\n",
    "    print('Epoch {}, Train Loss: {}, Test Loss: {}, Time: {}'.format(epoch, train_epoch_loss, test_epoch_loss, datetime.now()))\n",
    "\n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002]\n",
      "Epoch 1, Train Loss: 3.118236747862798, Test Loss: 0, Time: 2022-06-14 15:50:19.654098\n",
      "[0.00198]\n",
      "Epoch 2, Train Loss: 2.5659898796687086, Test Loss: 0, Time: 2022-06-14 15:51:08.763738\n",
      "[0.0019602]\n",
      "Epoch 3, Train Loss: 2.2963023132445297, Test Loss: 0, Time: 2022-06-14 15:51:57.289883\n",
      "[0.0019405980000000002]\n",
      "Epoch 4, Train Loss: 2.107021728691601, Test Loss: 0, Time: 2022-06-14 15:52:45.748685\n",
      "[0.0019211920199999999]\n",
      "Epoch 5, Train Loss: 1.963261037079292, Test Loss: 0, Time: 2022-06-14 15:53:34.334314\n",
      "[0.0019019800997999998]\n",
      "Epoch 6, Train Loss: 1.8559436748355522, Test Loss: 0, Time: 2022-06-14 15:54:23.040593\n",
      "[0.001882960298802]\n",
      "Epoch 7, Train Loss: 1.7683163637419712, Test Loss: 0, Time: 2022-06-14 15:55:11.741949\n",
      "[0.0018641306958139799]\n",
      "Epoch 8, Train Loss: 1.7029455500910606, Test Loss: 0, Time: 2022-06-14 15:56:00.478769\n",
      "[0.0018454893888558402]\n",
      "Epoch 9, Train Loss: 1.6414223944675832, Test Loss: 0, Time: 2022-06-14 15:56:49.248174\n",
      "[0.0018270344949672817]\n",
      "Epoch 10, Train Loss: 1.5951620908973239, Test Loss: 0, Time: 2022-06-14 15:57:38.085790\n",
      "[0.0018087641500176088]\n",
      "Epoch 11, Train Loss: 1.5550495042113575, Test Loss: 0, Time: 2022-06-14 15:58:27.149781\n",
      "[0.0017906765085174327]\n",
      "Epoch 12, Train Loss: 1.5179441816044785, Test Loss: 0, Time: 2022-06-14 15:59:16.144270\n",
      "[0.0017727697434322585]\n",
      "Epoch 13, Train Loss: 1.4913609156045962, Test Loss: 0, Time: 2022-06-14 16:00:04.611038\n",
      "[0.0017550420459979358]\n",
      "Epoch 14, Train Loss: 1.4640508645437145, Test Loss: 0, Time: 2022-06-14 16:00:53.238350\n",
      "[0.0017374916255379566]\n",
      "Epoch 15, Train Loss: 1.4309021876572776, Test Loss: 0, Time: 2022-06-14 16:01:41.808798\n",
      "[0.001720116709282577]\n",
      "Epoch 16, Train Loss: 1.4153649103343828, Test Loss: 0, Time: 2022-06-14 16:02:32.018197\n",
      "[0.0017029155421897512]\n",
      "Epoch 17, Train Loss: 1.3973684716356483, Test Loss: 0, Time: 2022-06-14 16:03:20.978761\n",
      "[0.0016858863867678536]\n",
      "Epoch 18, Train Loss: 1.379974242811969, Test Loss: 0, Time: 2022-06-14 16:04:10.125346\n",
      "[0.001669027522900175]\n",
      "Epoch 19, Train Loss: 1.3623630314029904, Test Loss: 0, Time: 2022-06-14 16:04:58.941440\n",
      "[0.0016523372476711733]\n",
      "Epoch 20, Train Loss: 1.3433552970873477, Test Loss: 0, Time: 2022-06-14 16:05:47.428641\n",
      "[0.0016358138751944615]\n",
      "Epoch 21, Train Loss: 1.3280570651665542, Test Loss: 0, Time: 2022-06-14 16:06:36.408213\n",
      "[0.0016194557364425169]\n",
      "Epoch 22, Train Loss: 1.3128433077553796, Test Loss: 0, Time: 2022-06-14 16:07:25.004892\n",
      "[0.0016032611790780917]\n",
      "Epoch 23, Train Loss: 1.3049593538405415, Test Loss: 0, Time: 2022-06-14 16:08:14.287666\n",
      "[0.0015872285672873109]\n",
      "Epoch 24, Train Loss: 1.2908090699169832, Test Loss: 0, Time: 2022-06-14 16:09:03.125310\n",
      "[0.0015713562816144376]\n",
      "Epoch 25, Train Loss: 1.2754428846514125, Test Loss: 0, Time: 2022-06-14 16:09:51.601222\n",
      "[0.0015556427187982933]\n",
      "Epoch 26, Train Loss: 1.2630328151601735, Test Loss: 0, Time: 2022-06-14 16:10:40.093261\n",
      "[0.0015400862916103103]\n",
      "Epoch 27, Train Loss: 1.249666411497836, Test Loss: 0, Time: 2022-06-14 16:11:28.754701\n",
      "[0.001524685428694207]\n",
      "Epoch 28, Train Loss: 1.2337319408897813, Test Loss: 0, Time: 2022-06-14 16:12:17.457320\n",
      "[0.0015094385744072651]\n",
      "Epoch 29, Train Loss: 1.2225582154977916, Test Loss: 0, Time: 2022-06-14 16:13:06.209704\n",
      "[0.0014943441886631924]\n",
      "Epoch 30, Train Loss: 1.2082925166418272, Test Loss: 0, Time: 2022-06-14 16:13:55.036570\n",
      "[0.0014794007467765604]\n",
      "Epoch 31, Train Loss: 1.1961422415258995, Test Loss: 0, Time: 2022-06-14 16:14:43.809686\n",
      "[0.001464606739308795]\n",
      "Epoch 32, Train Loss: 1.192966725779045, Test Loss: 0, Time: 2022-06-14 16:15:32.568956\n",
      "[0.0014499606719157068]\n",
      "Epoch 33, Train Loss: 1.1800818166592464, Test Loss: 0, Time: 2022-06-14 16:16:21.264787\n",
      "[0.0014354610651965498]\n",
      "Epoch 34, Train Loss: 1.171000448936805, Test Loss: 0, Time: 2022-06-14 16:17:10.151675\n",
      "[0.0014211064545445842]\n",
      "Epoch 35, Train Loss: 1.1593831328928443, Test Loss: 0, Time: 2022-06-14 16:17:59.188149\n",
      "[0.0014068953899991383]\n",
      "Epoch 36, Train Loss: 1.150311783117632, Test Loss: 0, Time: 2022-06-14 16:18:49.220640\n",
      "[0.001392826436099147]\n",
      "Epoch 37, Train Loss: 1.1383089816832823, Test Loss: 0, Time: 2022-06-14 16:19:40.699939\n",
      "[0.0013788981717381555]\n",
      "Epoch 38, Train Loss: 1.12700567938629, Test Loss: 0, Time: 2022-06-14 16:20:32.019346\n",
      "[0.0013651091900207738]\n",
      "Epoch 39, Train Loss: 1.121606138741396, Test Loss: 0, Time: 2022-06-14 16:21:23.468752\n",
      "[0.0013514580981205662]\n",
      "Epoch 40, Train Loss: 1.113964070848091, Test Loss: 0, Time: 2022-06-14 16:22:12.811746\n"
     ]
    }
   ],
   "source": [
    "n_pitches = len(note_to_int)\n",
    "hidden_size = 96\n",
    "n_layers = 2\n",
    "n_epochs = 40\n",
    "lr = 0.002\n",
    "lr_lambda = 0.99\n",
    "\n",
    "model = GenerationRNN(input_size = n_pitches, hidden_size = hidden_size, output_size = n_pitches, n_layers = n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: lr_lambda ** epoch)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_losses, test_losses = training_loop(model, optimizer, scheduler, criterion, train_input, train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 9\n",
    "model_name = 'RNN Single Note 14 May KP'\n",
    "save_path = os.path.join(dataRoot, model_name)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses over epochs\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label = 'Train Loss')\n",
    "plt.plot(test_losses, label = 'Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title(experiment_num)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to evaluate the language model i.e. generate new music\n",
    "\n",
    "def evaluate(net, prime_seq, predict_len):\n",
    "    '''\n",
    "    Arguments:\n",
    "    prime_seq - priming sequence (converted t)\n",
    "    predict_len - number of notes to predict for after prime sequence\n",
    "    '''\n",
    "    hidden = net.init_hidden()\n",
    "\n",
    "    predicted = prime_seq.copy()\n",
    "    prime_seq = torch.tensor(prime_seq, dtype = torch.long).to(device)\n",
    "\n",
    "\n",
    "    # \"Building up\" the hidden state using the prime sequence\n",
    "    for p in range(len(prime_seq) - 1):\n",
    "        input = prime_seq[p]\n",
    "        _, hidden = net(input, hidden)\n",
    "    \n",
    "    # Last character of prime sequence\n",
    "    input = prime_seq[-1]\n",
    "    \n",
    "    # For every index to predict\n",
    "    for p in range(predict_len):\n",
    "\n",
    "        # Pass the inputs to the model - output has dimension n_pitches - scores for each of the possible characters\n",
    "        output, hidden = net(input, hidden)\n",
    "\n",
    "        # Pick the character with the highest probability \n",
    "        predicted_id = torch.argmax(torch.softmax(output, dim = 1))\n",
    "\n",
    "        # Add predicted index to the list and use as next input\n",
    "        predicted.append(predicted_id.item()) \n",
    "        input = predicted_id\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMultinomial(net, prime_seq, predict_len, temperature=0.8):\n",
    "    '''\n",
    "    Arguments:\n",
    "    prime_seq - priming sequence (converted t)\n",
    "    predict_len - number of notes to predict for after prime sequence\n",
    "    '''\n",
    "    hidden = net.init_hidden()\n",
    "\n",
    "    predicted = prime_seq.copy()\n",
    "    prime_seq = torch.tensor(prime_seq, dtype = torch.long).to(device)\n",
    "\n",
    "\n",
    "    # \"Building up\" the hidden state using the prime sequence\n",
    "    for p in range(len(prime_seq) - 1):\n",
    "        input = prime_seq[p]\n",
    "        _, hidden = net(input, hidden)\n",
    "    \n",
    "    # Last character of prime sequence\n",
    "    input = prime_seq[-1]\n",
    "    \n",
    "    # For every index to predict\n",
    "    for p in range(predict_len):\n",
    "\n",
    "        # Pass the inputs to the model - output has dimension n_pitches - scores for each of the possible characters\n",
    "        output, hidden = net(input, hidden)\n",
    "        # Sample from the network output as a multinomial distribution\n",
    "        output = output.data.view(-1).div(temperature).exp()\n",
    "        predicted_id = torch.multinomial(output, 1)\n",
    "\n",
    "        # Add predicted index to the list and use as next input\n",
    "        predicted.append(predicted_id.item()) \n",
    "        input = predicted_id\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 102, 101, 100, 482, 648, 648, 900, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519]\n",
      "[100, 101, 102, 101, 100, 248, 910, 943, 884, 409, 928, 944, 825, 292, 944, 953, 519, 507, 878, 519, 902, 944, 944, 856, 731, 315, 262, 944, 523, 970, 482, 523, 262, 684, 523, 262, 684, 943, 942, 684, 830, 830, 653, 900, 653, 519, 292, 970, 746, 970, 614, 482, 678, 943, 786, 678, 941, 941, 283, 806, 830, 825, 944, 141, 943, 482, 952, 972, 583, 523, 684, 81, 684, 830, 684, 879, 523, 684, 927, 294, 372, 278, 291, 291, 291, 291, 291, 291, 291, 291, 262, 879, 262, 901, 910, 291, 952, 598, 879, 943, 598, 291, 291, 291, 291, 291, 807, 291, 291, 291, 75, 952, 452, 883, 824, 953, 684, 944, 475, 902, 339, 943, 684, 278, 884, 943, 856, 479, 830, 519, 583, 786, 291, 601, 428, 971, 291, 597, 291, 601, 952, 597, 291, 597, 291, 597, 291, 597, 291, 601, 597, 786, 952, 184, 597, 901, 597, 900, 901, 519, 900, 519, 598, 184, 952, 952, 894, 971, 952, 943, 952, 971, 952, 971, 952, 894, 894, 952, 952, 971, 952, 952, 971, 952, 952, 952, 151, 970, 901, 952, 901, 601, 971, 952, 971, 935, 598, 952, 598, 911, 894, 598, 952, 598, 950, 952, 598, 910, 598, 910, 598, 952, 598, 952, 952, 598, 910, 598, 950, 598, 597, 910, 598, 598, 597, 952, 952, 598, 597, 950, 598, 910, 598, 950, 597, 598, 597, 910, 601, 597, 597, 601, 597, 597, 597, 597, 950, 598, 953, 153, 953, 598, 953, 86, 598, 952, 184, 952, 598, 926, 598, 910, 428, 516, 909, 597, 193, 957, 830, 830, 910, 598, 943, 291, 952, 598, 952, 184, 909, 598, 184, 184, 952, 284, 184, 952, 184, 184, 952, 377, 449, 449, 746, 894, 952, 579, 599, 378, 909, 184, 952, 284, 135, 952, 894, 952, 911, 894, 601, 184, 427, 436, 601, 746, 449, 151, 428, 968, 268, 933, 428, 153, 894, 806, 598, 153, 598, 83, 156, 83, 597, 950, 598, 597, 156, 83, 741, 741, 449, 526, 597, 911, 156, 156, 86, 714, 598, 156, 86, 86, 714, 452, 950, 830, 950, 830, 806, 830, 598, 909, 950, 153, 950, 950, 153, 950, 899, 950, 597, 153, 950, 950, 950, 950, 153, 648, 950, 153, 950, 885, 909, 824, 950, 883, 950, 883, 950, 950, 824, 156, 900, 883, 941, 950, 950, 950, 825, 153, 950, 950, 223, 86, 950, 899, 291, 900, 935, 941, 774, 598, 952, 941, 653, 950, 223, 824, 806, 679, 925, 294, 883, 597, 950, 597, 950, 597, 950, 950, 950, 950, 950, 597, 950, 806, 950, 268, 598, 153, 927, 950, 597, 950, 950, 950, 950, 950, 825, 825, 950, 806, 156, 909, 950, 950, 950, 598, 950, 950, 597, 950, 66, 156, 156, 950, 156, 883, 950, 950, 648, 950, 885, 153, 885, 950, 885, 978, 825, 950, 950, 950, 825, 950, 153, 291, 899, 291, 950, 950, 684, 684, 806, 223, 86, 941, 900, 294, 900, 941, 283, 900, 941, 941, 941, 942, 900]\n"
     ]
    }
   ],
   "source": [
    "generated_seq = evaluate(model, [100, 101, 102, 101, 100], predict_len = 100)\n",
    "generated_seq_multinomial = evaluateMultinomial(model, [100, 101, 102, 101, 100], predict_len = 500, temperature = 1.2)\n",
    "print(generated_seq)\n",
    "print(generated_seq_multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated ints into notes\n",
    "generated_seq = [int_to_note[e] for e in generated_seq]\n",
    "generated_seq_multinomial = [int_to_note[e] for e in generated_seq_multinomial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting music21\n",
      "  Downloading music21-7.3.3-py3-none-any.whl (22.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.4 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/kennardpeters/.local/lib/python3.8/site-packages (from music21) (0.16.0)\n",
      "Requirement already satisfied: numpy in /home/kennardpeters/.local/lib/python3.8/site-packages (from music21) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /home/kennardpeters/.local/lib/python3.8/site-packages (from music21) (3.3.1)\n",
      "Requirement already satisfied: chardet in /usr/lib/python3/dist-packages (from music21) (3.0.4)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from music21) (4.2.0)\n",
      "Collecting webcolors>=1.5\n",
      "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib->music21) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from matplotlib->music21) (2.7.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->music21) (7.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib->music21) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib->music21) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib->music21) (0.10.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib->music21) (1.14.0)\n",
      "Installing collected packages: webcolors, jsonpickle, music21\n",
      "Successfully installed jsonpickle-2.2.0 music21-7.3.3 webcolors-1.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pypianoroll\n",
      "  Downloading pypianoroll-1.0.4-py3-none-any.whl (26 kB)\n",
      "Collecting pretty-midi>=0.2.8\n",
      "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 3.8 MB/s eta 0:00:01     |██████████                      | 1.8 MB 3.8 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/kennardpeters/.local/lib/python3.8/site-packages (from pypianoroll) (1.18.5)\n",
      "Requirement already satisfied: matplotlib>=1.5 in /home/kennardpeters/.local/lib/python3.8/site-packages (from pypianoroll) (3.3.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/kennardpeters/.local/lib/python3.8/site-packages (from pypianoroll) (1.4.1)\n",
      "Collecting mido>=1.1.16\n",
      "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.14.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib>=1.5->pypianoroll) (7.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib>=1.5->pypianoroll) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib>=1.5->pypianoroll) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from matplotlib>=1.5->pypianoroll) (2.7.3)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib>=1.5->pypianoroll) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kennardpeters/.local/lib/python3.8/site-packages (from matplotlib>=1.5->pypianoroll) (0.10.0)\n",
      "Building wheels for collected packages: pretty-midi\n",
      "  Building wheel for pretty-midi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591952 sha256=25b36ded357e8b42eede6ea6c7a65caf2848fd99c3e0ff4d641118a24c60e2f9\n",
      "  Stored in directory: /home/kennardpeters/.cache/pip/wheels/2a/5a/e3/30eeb9a99350f3f7e21258fcb132743eef1a4f49b3505e76b6\n",
      "Successfully built pretty-midi\n",
      "Installing collected packages: mido, pretty-midi, pypianoroll\n",
      "Successfully installed mido-1.2.10 pretty-midi-0.2.9 pypianoroll-1.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install music21\n",
    "%pip install pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord, stream\n",
    "import music21\n",
    "#import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    return midi_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kennardpeters/Documents/PyDrillData/14June_ca.mid'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_path = os.path.join(dataRoot, '14June_ca.mid')\n",
    "generated_stream = create_midi(generated_seq_multinomial)\n",
    "generated_stream.write('midi', fp=generated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
